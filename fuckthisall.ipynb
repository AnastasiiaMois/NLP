{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /anaconda3/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from fasttext) (1.16.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /anaconda3/lib/python3.7/site-packages (from fasttext) (41.0.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /anaconda3/lib/python3.7/site-packages (from fasttext) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import bz2\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR='/Users/anastasiamoiseva/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600000\n"
     ]
    }
   ],
   "source": [
    "data = bz2.BZ2File(DIR+\"/amazonreviews/train.ft.txt.bz2\")\n",
    "data = data.readlines()\n",
    "data = [x.decode('utf-8') for x in data]\n",
    "print(len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__1', '__label__2'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised('train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 number of records in the test set\n"
     ]
    }
   ],
   "source": [
    "test = bz2.BZ2File(DIR+\"/amazonreviews/test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test]\n",
    "print(len(test), 'number of records in the test set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [w.replace('__label__2 ', '') for w in test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]\n",
    "new = [w.replace('\\n', '') for w in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns = ['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Great CD: My lovely Pat has one of the GREAT v...\n",
       "1  One of the best game music soundtracks - for a...\n",
       "2  Batteries died within a year ...: I bought thi...\n",
       "3  works fine, but Maha Energy is better: Check o...\n",
       "4  Great for the non-audiophile: Reviewed quite a..."
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2'] is the predicted label\n",
      "['__label__2'] is the probability score\n"
     ]
    }
   ],
   "source": [
    "print(pred[0][0], 'is the predicted label')\n",
    "print(pred[0][1], 'is the probability score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91719\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforming labels into 0s ans 1s, \n",
    "0 - label_1 and 1 - label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_labels  = [0 if x.split(' ')[0] == '__label__1' else 1 for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = [w.replace('__label__2 ', '') for w in data]\n",
    "new_train = [w.replace('__label__1 ', '') for w in new]\n",
    "new_train = [w.replace('\\n', '') for w in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tr = pd.DataFrame(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Great CD: My lovely Pat has one of the GREAT v...\n",
       "1  One of the best game music soundtracks - for a...\n",
       "2  Batteries died within a year ...: I bought thi...\n",
       "3  works fine, but Maha Energy is better: Check o..."
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.DataFrame(new_train, dtype=str)\n",
    "data_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = ['Message', 'Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>Unbelievable- In a Bad Way: We bought this Tho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>Almost Great, Until it Broke...: My son reciev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>Disappointed !!!: I bought this toy for my son...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>Classic Jessica Mitford: This is a compilation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Comedy Scene, and Not Heard: This DVD will be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Message  Labels\n",
       "399995  Unbelievable- In a Bad Way: We bought this Tho...       1\n",
       "399996  Almost Great, Until it Broke...: My son reciev...       0\n",
       "399997  Disappointed !!!: I bought this toy for my son...       1\n",
       "399998  Classic Jessica Mitford: This is a compilation...       0\n",
       "399999  Comedy Scene, and Not Heard: This DVD will be ...       1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Labels'] = labels_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340716\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(lowercase=False).fit(data_train['Message'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_bow = bow_transformer.transform(data_train['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 2)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (400000, 340716)\n",
      "Amount of non-zero occurences: 22760250\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ',amazon_bow.shape)\n",
    "print('Amount of non-zero occurences:',amazon_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-9b128cb4968d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msparsity\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mamazon_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamazon_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mamazon_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sparsity:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "sparsity =(100.0 *amazon_bow.nnz/(amazon_bow.shape['Message']*amazon_bow.shape[1]))\n",
    "print('sparsity:{}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "works fine, but Maha Energy is better: Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\n"
     ]
    }
   ],
   "source": [
    "message4=data_train['Message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 479)\t1\n",
      "  (0, 3661)\t1\n",
      "  (0, 16499)\t1\n",
      "  (0, 31038)\t1\n",
      "  (0, 37478)\t1\n",
      "  (0, 56961)\t2\n",
      "  (0, 98470)\t1\n",
      "  (0, 100511)\t2\n",
      "  (0, 124559)\t1\n",
      "  (0, 157555)\t1\n",
      "  (0, 188972)\t2\n",
      "  (0, 190640)\t2\n",
      "  (0, 195657)\t1\n",
      "  (0, 199525)\t2\n",
      "  (0, 199533)\t1\n",
      "  (0, 230567)\t1\n",
      "  (0, 232401)\t3\n",
      "  (0, 241405)\t1\n",
      "  (0, 247481)\t1\n",
      "  (0, 252126)\t1\n",
      "  (0, 261087)\t1\n",
      "  (0, 266172)\t1\n",
      "  (0, 275856)\t1\n",
      "  (0, 276807)\t1\n",
      "  (0, 291535)\t1\n",
      "  (0, 307782)\t1\n",
      "  (0, 321364)\t1\n",
      "  (0, 335358)\t1\n",
      "  (0, 337360)\t1\n",
      "  (0, 338249)\t2\n",
      "(1, 340716)\n"
     ]
    }
   ],
   "source": [
    "bow4=bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 338249)\t0.1705579646334395\n",
      "  (0, 337360)\t0.03976565582701023\n",
      "  (0, 335358)\t0.12334808179757155\n",
      "  (0, 321364)\t0.057069492687200525\n",
      "  (0, 307782)\t0.15681912609077459\n",
      "  (0, 291535)\t0.17915094760195382\n",
      "  (0, 276807)\t0.05489020546153735\n",
      "  (0, 275856)\t0.1293923729376425\n",
      "  (0, 266172)\t0.09854872705107565\n",
      "  (0, 261087)\t0.21223183120828037\n",
      "  (0, 252126)\t0.02933826102716621\n",
      "  (0, 247481)\t0.03408429495220594\n",
      "  (0, 241405)\t0.04163513783867195\n",
      "  (0, 232401)\t0.1024374830521529\n",
      "  (0, 230567)\t0.09410370707694916\n",
      "  (0, 199533)\t0.13824837119640393\n",
      "  (0, 199525)\t0.2416619093286253\n",
      "  (0, 195657)\t0.04037133767437156\n",
      "  (0, 190640)\t0.1370243478657787\n",
      "  (0, 188972)\t0.23812091241481786\n",
      "  (0, 157555)\t0.13090757275492307\n",
      "  (0, 124559)\t0.24114221884528292\n",
      "  (0, 100511)\t0.4692905183070882\n",
      "  (0, 98470)\t0.21417630959208234\n",
      "  (0, 56961)\t0.37882071606953455\n",
      "  (0, 37478)\t0.1411995194245566\n",
      "  (0, 31038)\t0.26942481598567664\n",
      "  (0, 16499)\t0.08429141354688773\n",
      "  (0, 3661)\t0.21045666152495238\n",
      "  (0, 479)\t0.11451825536394708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer().fit(amazon_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 340716)\n"
     ]
    }
   ],
   "source": [
    "amazon_tfidf=tfidf_transformer.transform(amazon_bow)\n",
    "print(amazon_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(amazon_tfidf,data_train['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(amazon_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = spam_detect_model.predict()\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69    197932\n",
      "           1       0.69      0.83      0.75    202068\n",
      "\n",
      "    accuracy                           0.73    400000\n",
      "   macro avg       0.74      0.73      0.72    400000\n",
      "weighted avg       0.74      0.73      0.72    400000\n",
      "\n",
      "[[123628  74304]\n",
      " [ 34523 167545]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(data_train['Labels'],all_predictions))\n",
    "print(confusion_matrix(data_train['Labels'],all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7268749598224544\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(data_train['Labels'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so obviously the fasttext models performs better according to roc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: //anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    absl-py-0.9.0              |   py37hc8dfbb8_1         162 KB  conda-forge\n",
      "    astor-0.7.1                |             py_0          22 KB  conda-forge\n",
      "    c-ares-1.15.0              |    h01d97ff_1001          81 KB  conda-forge\n",
      "    gast-0.3.3                 |             py_0          12 KB  conda-forge\n",
      "    grpcio-1.23.0              |   py37h6ef0057_0         1.0 MB  conda-forge\n",
      "    keras-applications-1.0.8   |             py_1          30 KB  conda-forge\n",
      "    keras-preprocessing-1.1.0  |             py_0          33 KB  conda-forge\n",
      "    libprotobuf-3.9.2          |       hfbae3c0_0         4.4 MB  conda-forge\n",
      "    markdown-3.2.1             |             py_0          61 KB  conda-forge\n",
      "    protobuf-3.9.2             |   py37h6de7cb9_1         678 KB  conda-forge\n",
      "    tensorboard-1.13.1         |           py37_0         3.3 MB  conda-forge\n",
      "    tensorflow-1.13.1          |       hfddd6c2_8          22 KB  conda-forge\n",
      "    tensorflow-base-1.13.1     |           py37_8        58.9 MB  conda-forge\n",
      "    tensorflow-estimator-1.13.0|   py37h24bf2e0_0         473 KB  conda-forge\n",
      "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        69.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            conda-forge/osx-64::absl-py-0.9.0-py37hc8dfbb8_1\n",
      "  astor              conda-forge/noarch::astor-0.7.1-py_0\n",
      "  c-ares             conda-forge/osx-64::c-ares-1.15.0-h01d97ff_1001\n",
      "  gast               conda-forge/noarch::gast-0.3.3-py_0\n",
      "  grpcio             conda-forge/osx-64::grpcio-1.23.0-py37h6ef0057_0\n",
      "  keras-applications conda-forge/noarch::keras-applications-1.0.8-py_1\n",
      "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.0-py_0\n",
      "  libprotobuf        conda-forge/osx-64::libprotobuf-3.9.2-hfbae3c0_0\n",
      "  markdown           conda-forge/noarch::markdown-3.2.1-py_0\n",
      "  protobuf           conda-forge/osx-64::protobuf-3.9.2-py37h6de7cb9_1\n",
      "  tensorboard        conda-forge/osx-64::tensorboard-1.13.1-py37_0\n",
      "  tensorflow         conda-forge/osx-64::tensorflow-1.13.1-hfddd6c2_8\n",
      "  tensorflow-base    conda-forge/osx-64::tensorflow-base-1.13.1-py37_8\n",
      "  tensorflow-estima~ conda-forge/osx-64::tensorflow-estimator-1.13.0-py37h24bf2e0_0\n",
      "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2019.11.28-hecc5488_0 --> 2020.4.5.1-hecc5488_0\n",
      "  certifi                         2019.11.28-py37hc8dfbb8_1 --> 2020.4.5.1-py37hc8dfbb8_0\n",
      "  openssl                                 1.1.1e-h0b31af3_0 --> 1.1.1f-h0b31af3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "astor-0.7.1          | 22 KB     | ##################################### | 100% \n",
      "markdown-3.2.1       | 61 KB     | ##################################### | 100% \n",
      "termcolor-1.1.0      | 6 KB      | ##################################### | 100% \n",
      "tensorflow-1.13.1    | 22 KB     | ##################################### | 100% \n",
      "gast-0.3.3           | 12 KB     | ##################################### | 100% \n",
      "keras-applications-1 | 30 KB     | ##################################### | 100% \n",
      "tensorflow-estimator | 473 KB    | ##################################### | 100% \n",
      "c-ares-1.15.0        | 81 KB     | ##################################### | 100% \n",
      "tensorboard-1.13.1   | 3.3 MB    | ##################################### | 100% \n",
      "protobuf-3.9.2       | 678 KB    | ##################################### | 100% \n",
      "absl-py-0.9.0        | 162 KB    | ##################################### | 100% \n",
      "libprotobuf-3.9.2    | 4.4 MB    | ##################################### | 100% \n",
      "keras-preprocessing- | 33 KB     | ##################################### | 100% \n",
      "tensorflow-base-1.13 | 58.9 MB   | ##################################### | 100% \n",
      "grpcio-1.23.0        | 1.0 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  Labels\n",
       "0  Great CD: My lovely Pat has one of the GREAT v...       1\n",
       "1  One of the best game music soundtracks - for a...       1\n",
       "2  Batteries died within a year ...: I bought thi...       1\n",
       "3  works fine, but Maha Energy is better: Check o...       1\n",
       "4  Great for the non-audiophile: Reviewed quite a...       1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not an \"ultimate guide\": Firstly,I enjoyed the format and tone of the book (how the author addressed the reader). However, I did not feel that she imparted any insider secrets that the book promised to reveal. If you are just starting to research law school, and do not know all the requirements of admission, then this book may be a tremendous help. If you have done your homework and are looking for an edge when it comes to admissions, I recommend some more topic-specific books. For example, books on how to write your personal statment, books geared specifically towards LSAT preparation (Powerscore books were the most helpful for me), and there are some websites with great advice geared towards aiding the individuals whom you are asking to write letters of recommendation. Yet, for those new to the entire affair, this book can definitely clarify the requirements for you.'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['Message'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data_train['Message'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_train['Message'])\n",
    "X_test = tokenizer.texts_to_sequences(data_test['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Great CD: My lovely Pat has one of the GREAT v...\n",
       "1  One of the best game music soundtracks - for a...\n",
       "2  Batteries died within a year ...: I bought thi...\n",
       "3  works fine, but Maha Energy is better: Check o...\n",
       "4  Great for the non-audiophile: Reviewed quite a..."
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291459"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 100)          29145900  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100, 256)          25856     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100, 256)          65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100, 128)          32896     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 12801     \n",
      "=================================================================\n",
      "Total params: 29,283,245\n",
      "Trainable params: 137,345\n",
      "Non-trainable params: 29,145,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320000 samples, validate on 80000 samples\n",
      "Epoch 1/5\n",
      "320000/320000 [==============================] - 497s 2ms/step - loss: 0.6933 - acc: 0.5055 - val_loss: 0.6933 - val_acc: 0.4958\n",
      "Epoch 2/5\n",
      "320000/320000 [==============================] - 487s 2ms/step - loss: 0.6931 - acc: 0.5075 - val_loss: 0.6935 - val_acc: 0.4955\n",
      "Epoch 3/5\n",
      "320000/320000 [==============================] - 499s 2ms/step - loss: 0.6930 - acc: 0.5076 - val_loss: 0.6934 - val_acc: 0.4957\n",
      "Epoch 4/5\n",
      "320000/320000 [==============================] - 499s 2ms/step - loss: 0.6929 - acc: 0.5083 - val_loss: 0.6935 - val_acc: 0.4957\n",
      "Epoch 5/5\n",
      "320000/320000 [==============================] - 499s 2ms/step - loss: 0.6929 - acc: 0.5086 - val_loss: 0.6942 - val_acc: 0.4959\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000/400000 [==============================] - 232s 581us/step\n"
     ]
    }
   ],
   "source": [
    "ore = model.evaluate(X_test, labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6942033306646347\n",
      "Test Accuracy: 0.506737470626831\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", ore[0])\n",
    "print(\"Test Accuracy:\", ore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(labels, all_predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "model.add(LSTM(64))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320000 samples, validate on 80000 samples\n",
      "Epoch 1/6\n",
      "320000/320000 [==============================] - 2551s 8ms/step - loss: 0.6934 - acc: 0.5055 - val_loss: 0.6936 - val_acc: 0.4959\n",
      "Epoch 2/6\n",
      "320000/320000 [==============================] - 824s 3ms/step - loss: 0.6930 - acc: 0.5081 - val_loss: 0.6939 - val_acc: 0.4960\n",
      "Epoch 3/6\n",
      "320000/320000 [==============================] - 892s 3ms/step - loss: 0.6929 - acc: 0.5090 - val_loss: 0.6935 - val_acc: 0.4964\n",
      "Epoch 4/6\n",
      "320000/320000 [==============================] - 849s 3ms/step - loss: 0.6925 - acc: 0.5127 - val_loss: 0.6939 - val_acc: 0.4980\n",
      "Epoch 5/6\n",
      "320000/320000 [==============================] - 910s 3ms/step - loss: 0.6916 - acc: 0.5153 - val_loss: 0.6946 - val_acc: 0.4969\n",
      "Epoch 6/6\n",
      "320000/320000 [==============================] - 902s 3ms/step - loss: 0.6899 - acc: 0.5196 - val_loss: 0.6960 - val_acc: 0.5021\n",
      "400000/400000 [==============================] - 536s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6971812977552414\n",
      "Test Accuracy: 0.4834724962711334\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
